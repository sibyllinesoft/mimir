# OpenTelemetry Collector Configuration for Mimir-Lens Integration
# Comprehensive observability data collection and processing

# ==========================================================================
# RECEIVERS - Data collection endpoints
# ==========================================================================

receivers:
  # OTLP gRPC receiver (primary)
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size: 4194304  # 4MB
        max_concurrent_streams: 16
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - http://localhost:*
            - https://localhost:*

  # Prometheus metrics scraping
  prometheus/internal:
    config:
      global:
        scrape_interval: 30s
        external_labels:
          monitor: otel-collector
      scrape_configs:
        - job_name: 'otel-collector-internal'
          static_configs:
            - targets: ['0.0.0.0:8888']

  # Jaeger receiver (for legacy compatibility)
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Host metrics receiver
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
          system.disk.operations:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true
      process:
        metrics:
          process.cpu.utilization:
            enabled: true
          process.memory.utilization:
            enabled: true

# ==========================================================================
# PROCESSORS - Data transformation and enrichment
# ==========================================================================

processors:
  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  # Batch processor for efficiency
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Resource processor for service identification
  resource:
    attributes:
      - key: deployment.environment
        value: ${DEPLOYMENT_ENV}
        action: upsert
      - key: service.namespace
        value: mimir-lens
        action: upsert
      - key: service.version
        from_attribute: service.version
        action: upsert
      - key: host.name
        from_attribute: host.name
        action: upsert

  # Attributes processor for metric enrichment
  attributes/metrics:
    actions:
      - key: service_name
        from_attribute: service.name
        action: upsert
      - key: environment
        value: ${DEPLOYMENT_ENV}
        action: upsert

  # Transform processor for custom metrics
  transform:
    metric_statements:
      # Convert histogram to gauge for certain metrics
      - context: metric
        statements:
          - set(description, "Custom processed metric") where name == "custom_metric"
    
    trace_statements:
      # Add custom span attributes
      - context: span
        statements:
          - set(attributes["deployment.environment"], "${DEPLOYMENT_ENV}")
          - set(attributes["service.namespace"], "mimir-lens")

  # Filter processor to reduce noise
  filter/logs:
    error_mode: ignore
    logs:
      log_record:
        - 'body != nil and IsMatch(body, ".*DEBUG.*") == false'

  # Span processor for trace sampling
  probabilistic_sampler:
    hash_seed: 22
    sampling_percentage: 10

  # Grouping processor for correlated data
  groupbytrace:
    wait_duration: 10s
    num_traces: 1000

# ==========================================================================
# EXPORTERS - Data output destinations
# ==========================================================================

exporters:
  # Jaeger exporter for traces
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
    sending_queue:
      enabled: true
      num_consumers: 4
      queue_size: 100
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      environment: ${DEPLOYMENT_ENV}
      service_namespace: mimir-lens
    namespace: otel
    send_timestamps: true
    metric_expiration: 180s

  # Loki exporter for logs
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    tenant_id: "mimir-lens"
    labels:
      attributes:
        service.name: "service_name"
        service.version: "service_version"
        deployment.environment: "environment"
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # OTLP exporter for upstream collectors (optional)
  # otlp/upstream:
  #   endpoint: "https://your-observability-backend.com:4317"
  #   headers:
  #     api-key: "${OBSERVABILITY_API_KEY}"
  #   compression: gzip
  #   retry_on_failure:
  #     enabled: true
  #     initial_interval: 5s
  #     max_interval: 30s
  #     max_elapsed_time: 300s

  # Debug exporter (development only)
  debug:
    verbosity: normal
    sampling_initial: 2
    sampling_thereafter: 500

  # File exporter for debugging
  file:
    path: /tmp/otel-data.json
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 3

# ==========================================================================
# EXTENSIONS - Additional functionality
# ==========================================================================

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"

  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1777

  # Memory ballast for stability
  memory_ballast:
    size_mib: 128

  # File storage for queue persistence
  file_storage:
    directory: /tmp/otel-storage
    timeout: 1s

# ==========================================================================
# SERVICE PIPELINES - Data flow configuration
# ==========================================================================

service:
  # Extensions to load
  extensions: 
    - health_check
    - pprof
    - memory_ballast
    - file_storage

  pipelines:
    # Traces pipeline
    traces:
      receivers: 
        - otlp
        - jaeger
      processors:
        - memory_limiter
        - resource
        - batch
        - probabilistic_sampler
        - groupbytrace
      exporters: 
        - jaeger
        # - otlp/upstream  # Uncomment for upstream export
        # - debug  # Enable for debugging

    # Metrics pipeline
    metrics:
      receivers: 
        - otlp
        - prometheus/internal
        - hostmetrics
      processors:
        - memory_limiter
        - resource
        - attributes/metrics
        - transform
        - batch
      exporters: 
        - prometheus
        # - otlp/upstream  # Uncomment for upstream export

    # Logs pipeline
    logs:
      receivers: 
        - otlp
      processors:
        - memory_limiter
        - resource
        - filter/logs
        - batch
      exporters: 
        - loki
        # - otlp/upstream  # Uncomment for upstream export
        # - file  # Enable for debugging

  # Telemetry configuration
  telemetry:
    logs:
      level: "info"
      development: false
      sampling:
        initial: 2
        thereafter: 500
      encoding: "json"
    metrics:
      level: detailed
      address: 0.0.0.0:8888
      
    # Resource attributes for internal telemetry
    resource:
      service.name: "otel-collector"
      service.version: "0.86.0"
      deployment.environment: "${DEPLOYMENT_ENV}"